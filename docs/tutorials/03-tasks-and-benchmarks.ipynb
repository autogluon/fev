{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the following topics:\n",
    "1. Defining a time series forecasting `Task` consisting of multiple `EvaluationWindow`s\n",
    "2. Multivariate and univariate forecasting\n",
    "3. Evaluation on a `Benchmark` consisting of multiple tasks\n",
    "4. Aggregating benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import fev\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "datasets.disable_progress_bars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main classes\n",
    "The `fev` package provides 3 core classes for evaluating time series forecasting models:\n",
    "\n",
    "1. **`Task`** - Defines a single forecasting task with dataset path, forecast horizon, and evaluation settings. Each `Task` contains one or more evaluation windows.\n",
    "\n",
    "2. **`EvaluationWindow`** - Represents a single train/test split of the data at a specific cutoff point. Model performance is averaged across all windows within a `Task`.\n",
    "\n",
    "3. **`Benchmark`** - A collection of multiple tasks (e.g., different datasets). Individual task results are aggregated to compute overall benchmark scores.\n",
    "\n",
    "In short, the hierarchy is `Benchmark` -> `Task` -> `EvaluationWindow`.\n",
    "\n",
    "This tutorial demonstrates the functionality of these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data sources\n",
    "Dataset stored on Hugging Face Hub: https://huggingface.co/datasets/autogluon/chronos_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/chronos_datasets\",\n",
    "    dataset_config=\"monash_cif_2016\",\n",
    "    horizon=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset stored on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset consisting of a single parquet / arrow file\n",
    "task = fev.Task(\n",
    "    dataset_path=\"s3://autogluon/datasets/timeseries/m1_monthly/data.parquet\",\n",
    "    horizon=12,\n",
    ")\n",
    "# Dataset consisting of multiple parquet / arrow files\n",
    "task = fev.Task(\n",
    "    dataset_path=\"s3://autogluon/datasets/timeseries/m1_monthly/*.parquet\",\n",
    "    horizon=12,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset from HF Hub and save it locally\n",
    "ds = datasets.load_dataset(\"autogluon/chronos_datasets\", name=\"m4_hourly\", split=\"train\")\n",
    "local_path = \"/tmp/m4_hourly/data.parquet\"\n",
    "ds.to_parquet(local_path)\n",
    "\n",
    "task = fev.Task(\n",
    "    dataset_path=local_path,\n",
    "    horizon=48,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation windows\n",
    "A single `Task` consists of one or more `EvaluationWindow`s. \n",
    "\n",
    "Each `EvaluationWindow` represents a single train/test split of the time series data at a specific cutoff point.\n",
    "\n",
    "We'll create a task with a toy dataset to demonstrate how evaluation windows work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Create a toy dataset with a single time series\n",
    "ts = {\n",
    "    \"id\": \"A\",\n",
    "    \"timestamp\": pd.date_range(\"2025-01-01\", freq=\"D\", periods=10),\n",
    "    \"target\": list(range(10)),\n",
    "}\n",
    "ds = datasets.Dataset.from_list([ts])\n",
    "dataset_path = \"/tmp/toy_dataset.parquet\"\n",
    "ds.to_parquet(dataset_path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a `Task` with 2 evaluation windows based on this toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'target'],\n",
      "    num_rows: 1\n",
      "})\n",
      "{'id': np.str_('A'), 'timestamp': array(['2025-01-01T00:00:00.000000000', '2025-01-02T00:00:00.000000000',\n",
      "       '2025-01-03T00:00:00.000000000', '2025-01-04T00:00:00.000000000',\n",
      "       '2025-01-05T00:00:00.000000000', '2025-01-06T00:00:00.000000000',\n",
      "       '2025-01-07T00:00:00.000000000', '2025-01-08T00:00:00.000000000',\n",
      "       '2025-01-09T00:00:00.000000000', '2025-01-10T00:00:00.000000000'],\n",
      "      dtype='datetime64[ns]'), 'target': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}\n"
     ]
    }
   ],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    ")\n",
    "\n",
    "# Show the original dataset before any splits (for reference only)\n",
    "full_dataset = task.load_full_dataset()\n",
    "print(full_dataset)\n",
    "print(full_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's examine how the data is split across the 2 evaluation windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 0 (cutoff=-6):\n",
      "  Past data:    [0 1 2 3]\n",
      "  Ground truth: [4 5 6]\n",
      "Window 1 (cutoff=-3):\n",
      "  Past data:    [0 1 2 3 4 5 6]\n",
      "  Ground truth: [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Show how data is split across the 2 evaluation windows\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing evaluation window parameters\n",
    "You can control how evaluation windows are positioned using `initial_cutoff` and `window_step_size` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 0 (cutoff=-8):\n",
      "  Past data:    [0 1]\n",
      "  Ground truth: [2 3 4]\n",
      "Window 1 (cutoff=-5):\n",
      "  Past data:    [0 1 2 3 4]\n",
      "  Ground truth: [5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Start evaluation earlier with initial_cutoff\n",
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    "    initial_cutoff=-8,\n",
    ")\n",
    "\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 0 (cutoff=-4):\n",
      "  Past data:    [0 1 2 3 4 5]\n",
      "  Ground truth: [6 7 8]\n",
      "Window 1 (cutoff=-3):\n",
      "  Past data:    [0 1 2 3 4 5 6]\n",
      "  Ground truth: [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Use smaller window_step_size\n",
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    "    window_step_size=1,\n",
    ")\n",
    "\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also set `initial_cutoff` and `window_step_size` for pandas-compatible time strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 0 (cutoff=2025-01-05T00:00:00):\n",
      "  Past data:    [0 1 2 3 4]\n",
      "  Ground truth: [5 6 7]\n",
      "Window 1 (cutoff=2025-01-07T00:00:00):\n",
      "  Past data:    [0 1 2 3 4 5 6]\n",
      "  Ground truth: [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Use pandas timestamp-like strings\n",
    "task = fev.Task(\n",
    "    dataset_path=dataset_path,\n",
    "    horizon=3,\n",
    "    num_windows=2,\n",
    "    initial_cutoff=\"2025-01-05\",\n",
    "    window_step_size=\"2D\",\n",
    ")\n",
    "\n",
    "for window_index, window in enumerate(task.iter_windows()):\n",
    "    past, future = window.get_input_data()\n",
    "    ground_truth = window.get_ground_truth()\n",
    "    print(f\"Window {window_index} (cutoff={window.cutoff}):\")\n",
    "    print(f\"  Past data:    {past[0]['target']}\")\n",
    "    print(f\"  Ground truth: {ground_truth[0]['target']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate forecasting\n",
    "\n",
    "The simplest kind of forecasting task is univariate forecasting where the goal is to predict a single `target` for each time series in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/chronos_datasets\",\n",
    "    dataset_config=\"m4_hourly\",\n",
    "    horizon=24,\n",
    "    num_windows=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate a forecasting model on this task we need to make predictions for each `EvaluationWindow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions format\n",
    "Predictions must follow a certain format that is specified by `task.predictions_schema`.\n",
    "\n",
    "For point forecasting tasks (i.e., if `quantile_levels=None`), predictions must contain a single array of length `horizon` for each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': Sequence(feature=Value(dtype='float64', id=None), length=24, id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.predictions_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of a function that makes predictions for a single `EvaluationWindow` and formats them as a `datasets.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['predictions'],\n",
       "    num_rows: 414\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naive_forecast(window: fev.EvaluationWindow) -> datasets.Dataset:\n",
    "    assert len(window.target_columns) == 1, \"only univariate forecasting supported\"\n",
    "    predictions: list[dict[str, np.ndarray]] = []\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    for ts in past_data:\n",
    "        y = ts[window.target_columns[0]]\n",
    "        predictions.append(\n",
    "            {\"predictions\": np.array([y[-1] for _ in range(window.horizon)])}\n",
    "        )\n",
    "    return datasets.Dataset.from_list(predictions)\n",
    "\n",
    "window = task.get_window(0)\n",
    "predictions = naive_forecast(window)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in `predictions` is a dictionary where the key `\"predictions\"` corresponds to an array with `24` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0, 684.0]}\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have predictions for each evaluation window, we can compute the metrics and generate an evaluation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'naive',\n",
       " 'dataset_path': 'autogluon/chronos_datasets',\n",
       " 'dataset_config': 'm4_hourly',\n",
       " 'horizon': 24,\n",
       " 'num_windows': 2,\n",
       " 'initial_cutoff': -48,\n",
       " 'window_step_size': 24,\n",
       " 'min_context_length': 1,\n",
       " 'max_context_length': None,\n",
       " 'seasonality': 1,\n",
       " 'eval_metric': 'MASE',\n",
       " 'extra_metrics': [],\n",
       " 'quantile_levels': [],\n",
       " 'id_column': 'id',\n",
       " 'timestamp_column': 'timestamp',\n",
       " 'target': 'target',\n",
       " 'generate_univariate_targets_from': None,\n",
       " 'known_dynamic_columns': [],\n",
       " 'past_dynamic_columns': [],\n",
       " 'static_columns': [],\n",
       " 'task_name': 'm4_hourly',\n",
       " 'test_error': 3.8851860313085385,\n",
       " 'training_time_s': None,\n",
       " 'inference_time_s': None,\n",
       " 'dataset_fingerprint': '19e36bb78b718d8d',\n",
       " 'trained_on_this_dataset': False,\n",
       " 'fev_version': '0.6.0',\n",
       " 'MASE': 3.8851860313085385}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_per_window = [naive_forecast(window) for window in task.iter_windows()]\n",
    "task.evaluation_summary(predictions_per_window, model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For probabilistic forecasting tasks (i.e., if `quantile_levels` contains at least one value), predictions must additionally contain a prediction for each quantile level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/chronos_datasets\",\n",
    "    dataset_config=\"m4_hourly\",\n",
    "    horizon=24,\n",
    "    quantile_levels=[0.1, 0.5, 0.9],\n",
    "    eval_metric=\"WQL\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': Sequence(feature=Value(dtype='float64', id=None), length=24, id=None),\n",
       " '0.1': Sequence(feature=Value(dtype='float64', id=None), length=24, id=None),\n",
       " '0.5': Sequence(feature=Value(dtype='float64', id=None), length=24, id=None),\n",
       " '0.9': Sequence(feature=Value(dtype='float64', id=None), length=24, id=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.predictions_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariates\n",
    "By default, only the `id_column`, `timestamp_column` and `target` columns are loaded from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'transactions'],\n",
      "    num_rows: 51\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'timestamp'],\n",
      "    num_rows: 51\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"favorita_transactions_1D\",\n",
    "    horizon=7,\n",
    "    target=\"transactions\",\n",
    ")\n",
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view all the columns available in the dataset with `Task.load_full_dataset()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'transactions', 'oil_price', 'holiday', 'store_nbr', 'city', 'state', 'type', 'cluster'],\n",
      "    num_rows: 51\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='string', id=None),\n",
       " 'timestamp': Sequence(feature=Value(dtype='timestamp[ms]', id=None), length=-1, id=None),\n",
       " 'transactions': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
       " 'oil_price': Sequence(feature=Value(dtype='float32', id=None), length=-1, id=None),\n",
       " 'holiday': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'store_nbr': Value(dtype='float32', id=None),\n",
       " 'city': Value(dtype='string', id=None),\n",
       " 'state': Value(dtype='string', id=None),\n",
       " 'type': Value(dtype='string', id=None),\n",
       " 'cluster': Value(dtype='float32', id=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds = task.load_full_dataset()\n",
    "print(full_ds)\n",
    "full_ds.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can configure the task to use the additional columns as **covariates**. There are 3 types of covariates:\n",
    "\n",
    "Static covariates (`static_columns`) are the time-independent attributes of the time series, e.g.\n",
    "- Location (country, state, city)\n",
    "- Product properties (brand, color, size)\n",
    "- IDs and constant metadata\n",
    "\n",
    "Known dynamic covariates (`known_dynamic_columns`) are time-varying features available for both past and future periods, e.g.\n",
    "- Holidays, calendar features\n",
    "- Planned promotions\n",
    "\n",
    "Past dynamic covariates (`past_dynamic_columns`) are time-varying features only available until the forecast start, e.g.\n",
    "- Weather data, economic indicators\n",
    "- Related product sales\n",
    "\n",
    "Dynamic covariates must have feature type `Sequence` and length must match the target length for each row\n",
    "\n",
    "Static covariates must have feature type `Value` (not `Sequence`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'transactions', 'holiday', 'oil_price', 'city', 'state'],\n",
      "    num_rows: 51\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'holiday', 'city', 'state'],\n",
      "    num_rows: 51\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"favorita_transactions_1D\",\n",
    "    horizon=7,\n",
    "    target=\"transactions\",\n",
    "    known_dynamic_columns=[\"holiday\"],  # time-dependent, known in the future and in the past\n",
    "    past_dynamic_columns=[\"oil_price\"],  # time-dependent, known only in the past\n",
    "    static_columns=[\"city\", \"state\"],  # time-independent\n",
    ")\n",
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate forecasting\n",
    "In all previous examples we considered univariate forecasting tasks, where the goal was to predict a single `target` into the future. \n",
    "\n",
    "`fev` also supports multivariate tasks, where the goal is to simultaneously predict multiple target columns. \n",
    "\n",
    "### \"Real\" multivariate tasks\n",
    "We can define multivariate forecasting tasks by setting the `target` attribute to a `list` of column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"ETT_1H\",\n",
    "    horizon=3,\n",
    "    target=[\"OT\", \"LUFL\", \"LULL\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data created by the task in this case is identical to what would happen if we used `[\"OT\", \"LUFL\", \"LULL\"]` as `past_dynamic_columns`.\n",
    "That is, the target columns `[\"OT\", \"LUFL\", \"LULL\"]` are available in `past_data` but not in `future_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'LUFL', 'LULL', 'OT'],\n",
      "    num_rows: 2\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'timestamp'],\n",
      "    num_rows: 2\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference in a multivariate task is that the predictions must be formatted as a `datasets.DatasetDict` where\n",
    "- each key corresponds to the name of the target column\n",
    "- each value is a `datasets.Dataset` containing the predictions for this column in a format compatible with `task.predictions_schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_multivariate(window: fev.EvaluationWindow) -> datasets.DatasetDict:\n",
    "    \"\"\"Predicts the last observed value in each multivariate column.\"\"\"\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    predictions = datasets.DatasetDict()\n",
    "    for col in window.target_columns:\n",
    "        predictions_for_column = []\n",
    "        for ts in past_data:\n",
    "            predictions_for_column.append({\"predictions\": [ts[col][-1] for _ in range(window.horizon)]})\n",
    "        predictions[col] = datasets.Dataset.from_list(predictions_for_column)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    LUFL: Dataset({\n",
       "        features: ['predictions'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    LULL: Dataset({\n",
       "        features: ['predictions'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "    OT: Dataset({\n",
       "        features: ['predictions'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = task.get_window(0)\n",
    "predictions_per_window = naive_forecast_multivariate(window).cast(task.predictions_schema)\n",
    "predictions_per_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the individual values in the `Dataset` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for column 'LUFL'\n",
      "\t[{'predictions': [3.5329999923706055, 3.5329999923706055, 3.5329999923706055]}, {'predictions': [-10.331000328063965, -10.331000328063965, -10.331000328063965]}]\n",
      "Predictions for column 'LULL'\n",
      "\t[{'predictions': [1.6749999523162842, 1.6749999523162842, 1.6749999523162842]}, {'predictions': [-1.2899999618530273, -1.2899999618530273, -1.2899999618530273]}]\n",
      "Predictions for column 'OT'\n",
      "\t[{'predictions': [11.043999671936035, 11.043999671936035, 11.043999671936035]}, {'predictions': [48.18349838256836, 48.18349838256836, 48.18349838256836]}]\n"
     ]
    }
   ],
   "source": [
    "for col in task.target_columns:\n",
    "    print(f\"Predictions for column '{col}'\")\n",
    "    print(f\"\\t{predictions_per_window[col].to_list()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the code can stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'naive',\n",
       " 'dataset_path': 'autogluon/fev_datasets',\n",
       " 'dataset_config': 'ETT_1H',\n",
       " 'horizon': 3,\n",
       " 'num_windows': 1,\n",
       " 'initial_cutoff': -3,\n",
       " 'window_step_size': 3,\n",
       " 'min_context_length': 1,\n",
       " 'max_context_length': None,\n",
       " 'seasonality': 1,\n",
       " 'eval_metric': 'MASE',\n",
       " 'extra_metrics': [],\n",
       " 'quantile_levels': [],\n",
       " 'id_column': 'id',\n",
       " 'timestamp_column': 'timestamp',\n",
       " 'target': ['LUFL', 'LULL', 'OT'],\n",
       " 'generate_univariate_targets_from': None,\n",
       " 'known_dynamic_columns': [],\n",
       " 'past_dynamic_columns': [],\n",
       " 'static_columns': [],\n",
       " 'task_name': 'ETT_1H',\n",
       " 'test_error': 1.1921320279836811,\n",
       " 'training_time_s': None,\n",
       " 'inference_time_s': None,\n",
       " 'dataset_fingerprint': '305bfc1cf6779b47',\n",
       " 'trained_on_this_dataset': False,\n",
       " 'fev_version': '0.6.0',\n",
       " 'MASE': 1.1921320279836811}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.evaluation_summary([predictions_per_window], model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting multivariate tasks into univariate tasks\n",
    "Alternatively, we can convert a multivariate task into a univariate one by creating multiple univariate time series from each multivariate time series.\n",
    "\n",
    "The original `ETTh` dataset contains two multivariate time series with the following ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ETTh1', 'ETTh2'], dtype='<U5')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_data[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set `generate_univariate_targets_from=[\"OT\", \"LUFL\", \"LULL\"]`, `fev` will create 3 univariate time series from each time series in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = fev.Task(\n",
    "    dataset_path=\"autogluon/fev_datasets\",\n",
    "    dataset_config=\"ETT_1H\",\n",
    "    horizon=3,\n",
    "    generate_univariate_targets_from=[\"OT\", \"LUFL\", \"LULL\"],\n",
    "    target=\"target\",  # new name for the target columns ['OT', 'LUFL', 'LULL'] after splitting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'timestamp', 'target'],\n",
      "    num_rows: 6\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'timestamp'],\n",
      "    num_rows: 6\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "past_data, future_data = task.get_window(0).get_input_data()\n",
    "print(past_data)\n",
    "print(future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataset contains 6 items (2 original ids $\\times$ 3 target columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ETTh1_LUFL', 'ETTh1_LULL', 'ETTh1_OT', 'ETTh2_LUFL', 'ETTh2_LULL',\n",
       "       'ETTh2_OT'], dtype='<U10')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_data[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the naive forecast achieves the same MASE score on this equivalent representation of the multivariate task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_forecast_univariate(window: fev.EvaluationWindow) -> datasets.Dataset:\n",
    "    \"\"\"Predicts the last observed value.\"\"\"\n",
    "    past_data, future_data = window.get_input_data()\n",
    "    predictions = []\n",
    "    for ts in past_data:\n",
    "        predictions.append({\"predictions\": [ts[window.target_columns[0]][-1] for _ in range(window.horizon)]})\n",
    "    return datasets.Dataset.from_list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'naive',\n",
       " 'dataset_path': 'autogluon/fev_datasets',\n",
       " 'dataset_config': 'ETT_1H',\n",
       " 'horizon': 3,\n",
       " 'num_windows': 1,\n",
       " 'initial_cutoff': -3,\n",
       " 'window_step_size': 3,\n",
       " 'min_context_length': 1,\n",
       " 'max_context_length': None,\n",
       " 'seasonality': 1,\n",
       " 'eval_metric': 'MASE',\n",
       " 'extra_metrics': [],\n",
       " 'quantile_levels': [],\n",
       " 'id_column': 'id',\n",
       " 'timestamp_column': 'timestamp',\n",
       " 'target': 'target',\n",
       " 'generate_univariate_targets_from': ['OT', 'LUFL', 'LULL'],\n",
       " 'known_dynamic_columns': [],\n",
       " 'past_dynamic_columns': [],\n",
       " 'static_columns': [],\n",
       " 'task_name': 'ETT_1H',\n",
       " 'test_error': 1.1921320279836811,\n",
       " 'training_time_s': None,\n",
       " 'inference_time_s': None,\n",
       " 'dataset_fingerprint': '81591e84125d0e33',\n",
       " 'trained_on_this_dataset': False,\n",
       " 'fev_version': '0.6.0',\n",
       " 'MASE': 1.1921320279836811}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_per_window = []\n",
    "for window in task.iter_windows():\n",
    "    predictions_per_window.append(naive_forecast_univariate(window))\n",
    "task.evaluation_summary(predictions_per_window, model_name=\"naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on a Benchmark consisting of multiple tasks\n",
    "A `fev.Benchmark` object is essentially a collection of `Task`s.\n",
    "\n",
    "We can create a benchmark from a list of dictionaries. Each dictionary is interpreted as a `fev.TaskGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_configs = [\n",
    "    {\n",
    "        \"dataset_path\": \"autogluon/chronos_datasets\",\n",
    "        \"dataset_config\": \"monash_m1_quarterly\",\n",
    "        \"horizon\": 8,\n",
    "        \"seasonality\": 4,\n",
    "        \"eval_metric\": \"MASE\",\n",
    "    },\n",
    "    {\n",
    "        \"dataset_path\": \"autogluon/chronos_datasets\",\n",
    "        \"dataset_config\": \"monash_electricity_weekly\",\n",
    "        \"horizon\": 8,\n",
    "        \"num_windows\": 2,\n",
    "    },\n",
    "]\n",
    "benchmark = fev.Benchmark.from_list(tasks_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or from a YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasks:\n",
      "- dataset_path: autogluon/chronos_datasets\n",
      "  dataset_config: monash_m1_quarterly\n",
      "  horizon: 8\n",
      "  seasonality: 4\n",
      "- dataset_path: autogluon/chronos_datasets\n",
      "  dataset_config: monash_electricity_weekly\n",
      "  horizon: 8\n",
      "  num_windows: 2\n"
     ]
    }
   ],
   "source": [
    "benchmark_path = Path(fev.__file__).parents[2] / \"benchmarks\" / \"example\" / \"tasks.yaml\"\n",
    "# Show contents of the benchmark YAML file\n",
    "!cat {benchmark_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = fev.Benchmark.from_yaml(benchmark_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Task(dataset_path='autogluon/chronos_datasets', dataset_config='monash_m1_quarterly', horizon=8, num_windows=1, initial_cutoff=-8, window_step_size=8, min_context_length=1, max_context_length=None, seasonality=4, eval_metric='MASE', extra_metrics=[], quantile_levels=[], id_column='id', timestamp_column='timestamp', target='target', generate_univariate_targets_from=None, known_dynamic_columns=[], past_dynamic_columns=[], static_columns=[], task_name='monash_m1_quarterly'),\n",
       " Task(dataset_path='autogluon/chronos_datasets', dataset_config='monash_electricity_weekly', horizon=8, num_windows=2, initial_cutoff=-16, window_step_size=8, min_context_length=1, max_context_length=None, seasonality=1, eval_metric='MASE', extra_metrics=[], quantile_levels=[], id_column='id', timestamp_column='timestamp', target='target', generate_univariate_targets_from=None, known_dynamic_columns=[], past_dynamic_columns=[], static_columns=[], task_name='monash_electricity_weekly')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate some simple forecasting models on this toy benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "# You might need to restart the notebook after installing the dependencies\n",
    "!pip install -q statsforecast \"numpy<=2.2\" \"scipy<1.16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import ARIMA, SeasonalNaive, Theta\n",
    "\n",
    "\n",
    "def predict_with_model(task: fev.Task, model_name: str = \"naive\") -> list[datasets.Dataset]:\n",
    "    assert len(task.target_columns) == 1, \"only univariate forecasting supported\"\n",
    "    if model_name == \"seasonal_naive\":\n",
    "        model = SeasonalNaive(season_length=task.seasonality)\n",
    "    elif model_name == \"theta\":\n",
    "        model = Theta(season_length=task.seasonality)\n",
    "    elif model_name == \"arima\":\n",
    "        model = ARIMA(season_length=task.seasonality)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_name: {model_name}\")\n",
    "\n",
    "    predictions_per_window = []\n",
    "    for window in task.iter_windows():\n",
    "        past_data, future_data = window.get_input_data()\n",
    "        predictions = [\n",
    "            {\"predictions\": model.forecast(y=ts[task.target], h=task.horizon)[\"mean\"]}\n",
    "            for ts in past_data\n",
    "        ]\n",
    "        predictions_per_window.append(datasets.Dataset.from_list(predictions))\n",
    "    return predictions_per_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f134fd17644706b52a435a07823f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tasks completed:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "summaries = []\n",
    "for task in tqdm(benchmark.tasks, desc=\"Tasks completed\"):\n",
    "    for model_name in [\"seasonal_naive\", \"arima\", \"theta\"]:\n",
    "        start_time = time.time()\n",
    "        predictions_per_window = predict_with_model(task, model_name=model_name)\n",
    "        infer_time_s = time.time() - start_time\n",
    "        eval_summary = task.evaluation_summary(\n",
    "            predictions_per_window,\n",
    "            model_name=model_name,\n",
    "            inference_time_s=infer_time_s,\n",
    "            training_time_s=0.0,\n",
    "        )\n",
    "\n",
    "        summaries.append(eval_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_score</th>\n",
       "      <th>skill_score_lower</th>\n",
       "      <th>skill_score_upper</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>win_rate_lower</th>\n",
       "      <th>win_rate_upper</th>\n",
       "      <th>median_training_time_s</th>\n",
       "      <th>median_inference_time_s</th>\n",
       "      <th>num_failures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>theta</th>\n",
       "      <td>0.090189</td>\n",
       "      <td>-0.008472</td>\n",
       "      <td>0.179197</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.944199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seasonal_naive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085131</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arima</th>\n",
       "      <td>-0.486422</td>\n",
       "      <td>-1.233565</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                skill_score  skill_score_lower  skill_score_upper  win_rate  \\\n",
       "model_name                                                                    \n",
       "theta              0.090189          -0.008472           0.179197       0.5   \n",
       "seasonal_naive     0.000000           0.000000           0.000000       0.5   \n",
       "arima             -0.486422          -1.233565           0.010796       0.5   \n",
       "\n",
       "                win_rate_lower  win_rate_upper  median_training_time_s  \\\n",
       "model_name                                                               \n",
       "theta                      0.0             1.0                     0.0   \n",
       "seasonal_naive             0.5             0.5                     0.0   \n",
       "arima                      0.0             1.0                     0.0   \n",
       "\n",
       "                median_inference_time_s  num_failures  \n",
       "model_name                                             \n",
       "theta                          0.944199             0  \n",
       "seasonal_naive                 0.085131             0  \n",
       "arima                          0.300522             0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fev.leaderboard(summaries, baseline_model=\"seasonal_naive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `leaderboard` method aggregates the performance into a single number.\n",
    "\n",
    "We can investigate the performance for individual tasks using the `pivot_table` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_name</th>\n",
       "      <th>arima</th>\n",
       "      <th>seasonal_naive</th>\n",
       "      <th>theta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_config</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>monash_electricity_weekly</th>\n",
       "      <td>2.508152</td>\n",
       "      <td>2.535526</td>\n",
       "      <td>2.557008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m1_quarterly</th>\n",
       "      <td>4.640312</td>\n",
       "      <td>2.077537</td>\n",
       "      <td>1.705247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_name                    arima  seasonal_naive     theta\n",
       "dataset_config                                               \n",
       "monash_electricity_weekly  2.508152        2.535526  2.557008\n",
       "monash_m1_quarterly        4.640312        2.077537  1.705247"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fev.pivot_table(summaries, task_columns=[\"dataset_config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>skill_score</th>\n",
       "      <th>skill_score_lower</th>\n",
       "      <th>skill_score_upper</th>\n",
       "      <th>win_rate</th>\n",
       "      <th>win_rate_lower</th>\n",
       "      <th>win_rate_upper</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <th>model_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">auto_arima</th>\n",
       "      <th>auto_arima</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_theta</th>\n",
       "      <td>-0.012491</td>\n",
       "      <td>-0.100199</td>\n",
       "      <td>0.053276</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seasonal_naive</th>\n",
       "      <td>0.130551</td>\n",
       "      <td>0.053222</td>\n",
       "      <td>0.203856</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">auto_theta</th>\n",
       "      <th>auto_arima</th>\n",
       "      <td>0.012337</td>\n",
       "      <td>-0.056274</td>\n",
       "      <td>0.091074</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_theta</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seasonal_naive</th>\n",
       "      <td>0.141278</td>\n",
       "      <td>0.061410</td>\n",
       "      <td>0.225403</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.925926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">seasonal_naive</th>\n",
       "      <th>auto_arima</th>\n",
       "      <td>-0.150154</td>\n",
       "      <td>-0.256054</td>\n",
       "      <td>-0.056214</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_theta</th>\n",
       "      <td>-0.164521</td>\n",
       "      <td>-0.290994</td>\n",
       "      <td>-0.065428</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.370370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seasonal_naive</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               skill_score  skill_score_lower  \\\n",
       "model_1        model_2                                          \n",
       "auto_arima     auto_arima         0.000000           0.000000   \n",
       "               auto_theta        -0.012491          -0.100199   \n",
       "               seasonal_naive     0.130551           0.053222   \n",
       "auto_theta     auto_arima         0.012337          -0.056274   \n",
       "               auto_theta         0.000000           0.000000   \n",
       "               seasonal_naive     0.141278           0.061410   \n",
       "seasonal_naive auto_arima        -0.150154          -0.256054   \n",
       "               auto_theta        -0.164521          -0.290994   \n",
       "               seasonal_naive     0.000000           0.000000   \n",
       "\n",
       "                               skill_score_upper  win_rate  win_rate_lower  \\\n",
       "model_1        model_2                                                       \n",
       "auto_arima     auto_arima               0.000000  0.500000        0.500000   \n",
       "               auto_theta               0.053276  0.481481        0.296296   \n",
       "               seasonal_naive           0.203856  0.814815        0.666667   \n",
       "auto_theta     auto_arima               0.091074  0.518519        0.333333   \n",
       "               auto_theta               0.000000  0.500000        0.500000   \n",
       "               seasonal_naive           0.225403  0.777778        0.629630   \n",
       "seasonal_naive auto_arima              -0.056214  0.185185        0.037037   \n",
       "               auto_theta              -0.065428  0.222222        0.074074   \n",
       "               seasonal_naive           0.000000  0.500000        0.500000   \n",
       "\n",
       "                               win_rate_upper  \n",
       "model_1        model_2                         \n",
       "auto_arima     auto_arima            0.500000  \n",
       "               auto_theta            0.666667  \n",
       "               seasonal_naive        0.962963  \n",
       "auto_theta     auto_arima            0.703704  \n",
       "               auto_theta            0.500000  \n",
       "               seasonal_naive        0.925926  \n",
       "seasonal_naive auto_arima            0.333333  \n",
       "               auto_theta            0.370370  \n",
       "               seasonal_naive        0.500000  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fev.pairwise_comparison(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `leaderboard()` and `pivot_table()` methods can handle single or multiple evaluation summaries in different formats:\n",
    "- `pandas.DataFrame`\n",
    "- list of dictionaries\n",
    "- paths to JSONL (orient=\"record\") or CSV files\n",
    "\n",
    "Here is an example of how we can work with URLs of CSV files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "baseline_model 'SeasonalNaive' not found. Available models: ['auto_arima', 'auto_theta', 'seasonal_naive']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m summaries = [\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/auto_arima.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/auto_theta.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/seasonal_naive.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m ]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mfev\u001b[49m\u001b[43m.\u001b[49m\u001b[43mleaderboard\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_column\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMASE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/fev/src/fev/analysis.py:270\u001b[39m, in \u001b[36mleaderboard\u001b[39m\u001b[34m(summaries, metric_column, missing_strategy, baseline_model, min_relative_error, max_relative_error, included_models, excluded_models, n_resamples, seed)\u001b[39m\n\u001b[32m    268\u001b[39m summaries = _load_summaries(summaries, check_fev_version=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    269\u001b[39m summaries = _filter_models(summaries, included_models=included_models, excluded_models=excluded_models)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m errors_df = \u001b[43mpivot_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m errors_df = errors_df.clip(lower=min_relative_error, upper=max_relative_error)\n\u001b[32m    273\u001b[39m num_failures_per_model = errors_df.isna().sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/fev/src/fev/analysis.py:183\u001b[39m, in \u001b[36mpivot_table\u001b[39m\u001b[34m(summaries, metric_column, task_columns, baseline_model, check_fev_version)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m baseline_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m baseline_model \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pivot_df.columns:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    184\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbaseline_model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaseline_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found. Available models: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpivot_df.columns.tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m         )\n\u001b[32m    186\u001b[39m     pivot_df = pivot_df.divide(pivot_df[baseline_model], axis=\u001b[32m0\u001b[39m)\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m num_baseline_failures := pivot_df[baseline_model].isna().sum():\n",
      "\u001b[31mValueError\u001b[39m: baseline_model 'SeasonalNaive' not found. Available models: ['auto_arima', 'auto_theta', 'seasonal_naive']"
     ]
    }
   ],
   "source": [
    "summaries = [\n",
    "    \"https://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/auto_arima.csv\",\n",
    "    \"https://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/auto_theta.csv\",\n",
    "    \"https://raw.githubusercontent.com/autogluon/fev/refs/heads/main/benchmarks/chronos_zeroshot/results/seasonal_naive.csv\",\n",
    "]\n",
    "fev.leaderboard(summaries, metric_column=\"MASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model_name</th>\n",
       "      <th>auto_arima</th>\n",
       "      <th>auto_theta</th>\n",
       "      <th>seasonal_naive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_config</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ETTh</th>\n",
       "      <td>0.089012</td>\n",
       "      <td>0.132979</td>\n",
       "      <td>0.122090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETTm</th>\n",
       "      <td>0.104990</td>\n",
       "      <td>0.078587</td>\n",
       "      <td>0.141348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dominick</th>\n",
       "      <td>0.484773</td>\n",
       "      <td>0.485493</td>\n",
       "      <td>0.452916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ercot</th>\n",
       "      <td>0.041214</td>\n",
       "      <td>0.041004</td>\n",
       "      <td>0.036604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange_rate</th>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>0.012984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m4_quarterly</th>\n",
       "      <td>0.079384</td>\n",
       "      <td>0.079077</td>\n",
       "      <td>0.118648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m4_yearly</th>\n",
       "      <td>0.125041</td>\n",
       "      <td>0.114640</td>\n",
       "      <td>0.161439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m5</th>\n",
       "      <td>0.616520</td>\n",
       "      <td>0.636228</td>\n",
       "      <td>1.024088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_australian_electricity</th>\n",
       "      <td>0.066902</td>\n",
       "      <td>0.054564</td>\n",
       "      <td>0.083695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_car_parts</th>\n",
       "      <td>1.333026</td>\n",
       "      <td>1.336601</td>\n",
       "      <td>1.599952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_cif_2016</th>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.027333</td>\n",
       "      <td>0.015083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_covid_deaths</th>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.094479</td>\n",
       "      <td>0.133085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_fred_md</th>\n",
       "      <td>0.035140</td>\n",
       "      <td>0.057386</td>\n",
       "      <td>0.122224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_hospital</th>\n",
       "      <td>0.058569</td>\n",
       "      <td>0.055279</td>\n",
       "      <td>0.072626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m1_monthly</th>\n",
       "      <td>0.154444</td>\n",
       "      <td>0.159026</td>\n",
       "      <td>0.191463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m1_quarterly</th>\n",
       "      <td>0.088292</td>\n",
       "      <td>0.082034</td>\n",
       "      <td>0.149502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m1_yearly</th>\n",
       "      <td>0.132822</td>\n",
       "      <td>0.137302</td>\n",
       "      <td>0.209296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m3_monthly</th>\n",
       "      <td>0.098059</td>\n",
       "      <td>0.094722</td>\n",
       "      <td>0.148545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m3_quarterly</th>\n",
       "      <td>0.076532</td>\n",
       "      <td>0.070173</td>\n",
       "      <td>0.101252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_m3_yearly</th>\n",
       "      <td>0.155759</td>\n",
       "      <td>0.127728</td>\n",
       "      <td>0.166533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_nn5_weekly</th>\n",
       "      <td>0.084427</td>\n",
       "      <td>0.089608</td>\n",
       "      <td>0.122691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_tourism_monthly</th>\n",
       "      <td>0.090934</td>\n",
       "      <td>0.090997</td>\n",
       "      <td>0.104182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_tourism_quarterly</th>\n",
       "      <td>0.099659</td>\n",
       "      <td>0.061241</td>\n",
       "      <td>0.119375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_tourism_yearly</th>\n",
       "      <td>0.128889</td>\n",
       "      <td>0.176017</td>\n",
       "      <td>0.209183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_traffic</th>\n",
       "      <td>0.353603</td>\n",
       "      <td>0.905307</td>\n",
       "      <td>0.361853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monash_weather</th>\n",
       "      <td>0.214781</td>\n",
       "      <td>0.216555</td>\n",
       "      <td>0.216595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nn5</th>\n",
       "      <td>0.247710</td>\n",
       "      <td>0.293651</td>\n",
       "      <td>0.424621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model_name                     auto_arima  auto_theta  seasonal_naive\n",
       "dataset_config                                                       \n",
       "ETTh                             0.089012    0.132979        0.122090\n",
       "ETTm                             0.104990    0.078587        0.141348\n",
       "dominick                         0.484773    0.485493        0.452916\n",
       "ercot                            0.041214    0.041004        0.036604\n",
       "exchange_rate                    0.010667    0.009714        0.012984\n",
       "m4_quarterly                     0.079384    0.079077        0.118648\n",
       "m4_yearly                        0.125041    0.114640        0.161439\n",
       "m5                               0.616520    0.636228        1.024088\n",
       "monash_australian_electricity    0.066902    0.054564        0.083695\n",
       "monash_car_parts                 1.333026    1.336601        1.599952\n",
       "monash_cif_2016                  0.033184    0.027333        0.015083\n",
       "monash_covid_deaths              0.028973    0.094479        0.133085\n",
       "monash_fred_md                   0.035140    0.057386        0.122224\n",
       "monash_hospital                  0.058569    0.055279        0.072626\n",
       "monash_m1_monthly                0.154444    0.159026        0.191463\n",
       "monash_m1_quarterly              0.088292    0.082034        0.149502\n",
       "monash_m1_yearly                 0.132822    0.137302        0.209296\n",
       "monash_m3_monthly                0.098059    0.094722        0.148545\n",
       "monash_m3_quarterly              0.076532    0.070173        0.101252\n",
       "monash_m3_yearly                 0.155759    0.127728        0.166533\n",
       "monash_nn5_weekly                0.084427    0.089608        0.122691\n",
       "monash_tourism_monthly           0.090934    0.090997        0.104182\n",
       "monash_tourism_quarterly         0.099659    0.061241        0.119375\n",
       "monash_tourism_yearly            0.128889    0.176017        0.209183\n",
       "monash_traffic                   0.353603    0.905307        0.361853\n",
       "monash_weather                   0.214781    0.216555        0.216595\n",
       "nn5                              0.247710    0.293651        0.424621"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fev.pivot_table(summaries, task_columns=[\"dataset_config\"], metric_column=\"WQL\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
